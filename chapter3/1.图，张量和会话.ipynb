{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. 计算图的概念\n",
    "计算图是TF最基本的概念。\n",
    "TF本身，就是一个用计算图表述计算的编程系统：\n",
    "\n",
    "* Tensor是张量，在这里可以简单理解为多维数组；\n",
    "* Flow是流动的意思，因为张量之间通过计算相互转化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF中所有计算，都会被转化为计算图上的节点。节点之间的边（连线），描述了计算之间的依赖关系。\n",
    "\n",
    "比如运算a+b：\n",
    "\n",
    "* a和b都是一个节点，在TF中，常数被转化成一种恒定输出固定值的运算；\n",
    "* add也是一个节点，代表加法运算；\n",
    "* a和add、b和add之间有边，代表依赖关系。\n",
    "#### TF会自动将定义的计算转化为计算图上的节点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. 计算图的使用\n",
    "在TF中，系统会自动维护一个默认的计算图，可以通过tf.get_default_graph函数获取:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1.0,2.0],name=\"a\")\n",
    "print( a.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过tf.Graph 创建新的图\n",
    "#### 不同图上的张量和运算不能共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "#在计算图中g1 中定义v 设置初试值为0\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    v = tf.get_variable('v',shape=[1],initializer = tf.zeros_initializer)\n",
    "\n",
    "#在计算图中g2 中定义v 设置初试值为1\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    v = tf.get_variable('v',shape=[1],initializer = tf.ones_initializer)\n",
    "    \n",
    "#读取g1中的 v\n",
    "#步骤 1.创建graph 为g1 的session  2.初始化所有张量  3.设置scope  4.使用get_varilable\n",
    "with tf.Session(graph = g1) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    #可以让不同命名空间中的变量取相同的名字，无\n",
    "    #论tf.get_variable或者tf.Variable生成的变量\n",
    "    with tf.variable_scope('',reuse = True):\n",
    "        print(sess.run(tf.get_variable('v')))\n",
    "        \n",
    "#读取g2中的 v\n",
    "#步骤 1.创建graph 为g1 的session  2.初始化所有张量  3.设置scope  4.使用get_varilable\n",
    "with tf.Session(graph = g2) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope('',reuse = True):\n",
    "        print(sess.run(tf.get_variable('v')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不仅如此，还可以指定某运算图的GPU，借助tf.Graph.device函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=tf.Graph()\n",
    "with g.device('/gpu:0'):\n",
    "    result = 1 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.TensorFlow数据类型——张量\n",
    "#### 1.张量的概念\n",
    "从功能上，Tensor可以简单理解为多维数组。比如零阶张量就是标量scalar，一阶张量就是一个向量等。\n",
    "\n",
    "实际上张量的实现**并非采用保存数组的形式，而是保存计算过程。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_1:0\", shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1,2],name = 'a')\n",
    "b = tf.constant([5,8],name = 'b')\n",
    "result = tf.add(a,b,name='add')\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反映了tensor的三大属性 ：名字，维度，类型\n",
    "\n",
    "add:0：add节点输出的第一个结果（编号从0开始）。\n",
    "#### 2. 张量的使用\n",
    "我们知道，把一段长指令拆解成短指令，很多时候可以增强可读性。引用张量也有同样的效果。\n",
    "\n",
    "并且，张量相当于一个中间结果，尤其在构建深层网络时，可以方便获取。\n",
    "\n",
    "如果需要打印出具体值，需要开启会话，利用tf.Session().run(result)语句。这在后面介绍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 10]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、会话\n",
    "我们利用Session执行定义好的运算。\n",
    "\n",
    "Session拥有并管理TF程序运行时的所有资源。\n",
    "计算完成后，需要结束会话，否则会造成资源泄露。\n",
    "\n",
    "以下是一般格式：\n",
    "\n",
    "    1.创建会话；\n",
    "\n",
    "    2.用run运算出会话中感兴趣的值；\n",
    "\n",
    "    3.结束会话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant(1,name=\"a\")\n",
    "b=tf.constant(2,name=\"b\")\n",
    "result=a+b\n",
    "\n",
    "sess=tf.Session()\n",
    "print(sess.run(result))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以用eval方法直接计算一个张量的值。\n",
    "注意：\n",
    "\n",
    "   * eval是张量的方法，run是会话的方法，而会话一般属于默认运算图（如果没有指定）。\n",
    "   * TF会自动生成默认的运算图，但不会自动生成默认的会话。必须指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant(1,name=\"a\")\n",
    "b=tf.constant(2,name=\"b\")\n",
    "result=a+b\n",
    "\n",
    "sess=tf.Session() #选择的是默认的graph\n",
    "print(result.eval(session=sess)) # 必须有session=sess选项，No default session.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant(1,name=\"a\")\n",
    "b=tf.constant(2,name=\"b\")\n",
    "result=a+b\n",
    "\n",
    "sess = tf.InteractiveSession() # 该函数自动将生成的会话注册为默认会话\n",
    "print(result.eval())  #上面已经指定了默认会话\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意以上3个例程：\n",
    "\n",
    " 1.指定会话，在该会话中run\n",
    " \n",
    " 2.指定会话，在该会话中eval目标张量\n",
    " \n",
    " 3.指定默认会话，直接eval目标张量\n",
    "上述方式有一个共同问题：\n",
    "#### 如果程序异常而退出，则close将未执行，最终导致资源没有回收。\n",
    "\n",
    "为此，我们可以通过PY的上下文管理器使用会话：\n",
    "所有的运算都是with内部，只要管理器退出，资源就会被自动释放，异常退出同理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant(1,name=\"a\")\n",
    "b=tf.constant(2,name=\"b\")\n",
    "result=a+b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant(1,name=\"a\")\n",
    "b=tf.constant(2,name=\"b\")\n",
    "result=a+b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(result.eval(session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant(1,name=\"a\")\n",
    "b=tf.constant(2,name=\"b\")\n",
    "result=a+b\n",
    "\n",
    "sess=tf.Session()\n",
    "with sess.as_default(): # 注意设置为默认会话\n",
    "    print(result.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，ConfigProto Protocol Buffer可以增强配置。\n",
    "\n",
    "该结构数据序列化工具，可以配置类似并行的线程数、GPU分配策略、运算超时时间等参数。\n",
    "\n",
    "其中最常用的就是以下两个参数：\n",
    "\n",
    " * 布尔型参数allow_soft_placement\n",
    " * 默认为False。\n",
    " * 当其为True时，只要以下任意一个条件成立，GPU上的运算都会放到CPU上进行：\n",
    " * 运算在GPU上无法执行；\n",
    " * 没有指定GPU资源，比如只有一个GPU，但运算指定在第二个GPU上执行；\n",
    " * 运算输入包含对CPU运算结果的引用。\n",
    " * 该参数常设为True，这样可以增强代码的可移植性，可以在GPU异常或数目不确定的情况下正常运行程序。\n",
    "\n",
    "布尔型参数log_device_placement\n",
    "当其为True时，日志将会记录每个节点被安排在哪个设备上，方便调试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                       log_device_placement=True)\n",
    "sess1 = tf.InteractiveSession(config=config) # 创建默认会话\n",
    "sess2 = tf.Session(config=config) # 创建一般会话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
